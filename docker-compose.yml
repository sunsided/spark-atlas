# https://github.com/big-data-europe/docker-spark
version: "3.6"

services:
  jupyterlab:
    image: jupyter/pyspark-notebook:spark-3.3.0
    container_name: jupyterlab
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=5f69150501c3c0c4f94f5d4ae38123e2f556777f794bf48b
      - GRANT_SUDO=yes
    ports:
      - "8888:8888"
    volumes:
      - shared-workspace:/opt/workspace
      - type: bind
        source: notebooks/
        target: /home/jovyan/notebooks

  spark-master:
    build:
      dockerfile: Dockerfile
      context: spark
      args:
        flavor: master
    image: spark-master
    container_name: spark-master
    environment:
      - SPARK_PACKAGES=org.mongodb.spark:mongo-spark-connector_2.12:10.2.0
    expose:
      - 7077
    ports:
      - "8090:8080"
      - "7077:7077"
    volumes:
      - shared-workspace:/opt/workspace
      #- type: bind
      #  read_only: true
      #  source: jars/
      #  target: /spark/extra-jars

  spark-worker-1:
    build:
      dockerfile: Dockerfile
      context: spark
      args:
        flavor: worker
    image: spark-worker
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=4g
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_PACKAGES=org.mongodb.spark:mongo-spark-connector_2.12:10.2.0
    ports:
      - "8081:8081"
    volumes:
      - shared-workspace:/opt/workspace
      #- type: bind
      #  read_only: true
      #  source: jars/
      #  target: /spark/extra-jars
    depends_on:
      - spark-master

  spark-worker-2:
    build:
      dockerfile: Dockerfile
      context: spark
      args:
        flavor: worker
    image: spark-worker
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=4g
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_PACKAGES=org.mongodb.spark:mongo-spark-connector_2.12:10.2.0
    ports:
      - "8082:8081"
    volumes:
      - shared-workspace:/opt/workspace
      #- type: bind
      #  read_only: true
      #  source: jars/
      #  target: /spark/extra-jars
    depends_on:
      - spark-master

  spark-history-server:
    image: bde2020/spark-history-server:3.3.0-hadoop3.3
    container_name: spark-history-server
    depends_on:
      - spark-master
    ports:
      - "18081:18081"
    volumes:
      - /tmp/spark-events-local:/tmp/spark-events

volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
  notebooks:
    driver: local