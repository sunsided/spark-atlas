# https://github.com/big-data-europe/docker-spark
version: "3.6"

services:
  jupyterlab:
    build:
      context: jupyter
      dockerfile: Dockerfile
    image: pyspark-notebook
    container_name: jupyterlab
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=5f69150501c3c0c4f94f5d4ae38123e2f556777f794bf48b
      - GRANT_SUDO=yes
    ports:
      - "8888:8888"
    volumes:
      - shared-workspace:/opt/workspace
      - type: bind
        source: notebooks/
        target: /home/jovyan/notebooks

  spark-master:
    build:
      context: spark
      dockerfile: Dockerfile
      target: master
    image: spark-master
    container_name: spark-master
    environment:
      - SPARK_PUBLIC_DNS=spark-master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
    expose:
      - 7077
    ports:
      - "8090:8080"
      - "7077:7077"
    volumes:
      - shared-workspace:/opt/workspace
      #- type: bind
      #  read_only: true
      #  source: jars/
      #  target: /spark/extra-jars

  spark-worker-1:
    build:
      context: spark
      dockerfile: Dockerfile
      target: worker
    image: spark-worker
    container_name: spark-worker-1
    environment:
      - SPARK_PUBLIC_DNS=spark-worker-1
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=4g
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8081:8081"
      - "4041:4040"
    volumes:
      - shared-workspace:/opt/workspace
      #- type: bind
      #  read_only: true
      #  source: jars/
      #  target: /spark/extra-jars
    depends_on:
      - spark-master

  spark-worker-2:
    build:
      context: spark
      dockerfile: Dockerfile
      target: worker
    image: spark-worker
    container_name: spark-worker-2
    environment:
      - SPARK_PUBLIC_DNS=spark-worker-2
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=4g
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8082:8081"
      - "4042:4040"
    volumes:
      - shared-workspace:/opt/workspace
      #- type: bind
      #  read_only: true
      #  source: jars/
      #  target: /spark/extra-jars
    depends_on:
      - spark-master

  spark-history-server:
    image: bde2020/spark-history-server:3.2.0-hadoop3.2
    container_name: spark-history-server
    depends_on:
      - spark-master
    ports:
      - "18081:18081"
    volumes:
      - /tmp/spark-events-local:/tmp/spark-events

volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
  notebooks:
    driver: local